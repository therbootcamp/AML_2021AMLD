---
title: "Prediction"
author: "<table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'><col width='10%'><col width='10%'>
  <tr style='border:none'>
    <td style='display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none' nowrap>
      <font style='font-style:normal'>Applied Machine Learning with R</font><br>
      <a href='https://therbootcamp.github.io/AML_2021AMLD/'>
        <i class='fas fa-clock' style='font-size:.9em;' ></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <i class='fas fa-home' style='font-size:.9em;'></i>
      </a>
      <a href='mailto:therbootcamp@gmail.com'>
        <i class='fas fa-envelope' style='font-size: .9em;'></i>
      </a>
      <a href='https://www.linkedin.com/company/basel-r-bootcamp/'>
        <i class='fab fa-linkedin' style='font-size: .9em;'></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <font style='font-style:normal'>The R Bootcamp @ AMLD</font>
      </a>
    </td>
    <td style='width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none'>
      <img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
    </td>
  </tr></table>"
output:
  html_document:
    css: practical.css
    self_contained: no
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(comment = NA, 
                      fig.width = 6, 
                      fig.height = 6,
                      fig.align = 'center',
                      echo = FALSE, 
                      eval = FALSE, 
                      warning = FALSE,
                      message = FALSE)

options(digits = 3)
```

<p align="center">
<img width="100%" src="https://cdn-images-1.medium.com/max/1200/0*F0y1bmOEzCFCcPE_" margin=0><br>
<font style="font-size:10px">from [Medium.com](https://Medium.com/)</font>
</p>

# {.tabset}

## Overview

By the end of this practical you will know how to:

1. Fit regression, decision trees and random forests to training data.
2. Evaluate model fitting *and* prediction performance in a test set.
3. Compare the fitting and prediction performance of two models.
4. Explore the effects of features on model predictions.

## Tasks

### A - Setup

1. Open your `RBootcamp_AMLD2021` R project. It should already have the folders `1_Data` and `2_Code`. Make sure that the data file(s) listed in the `Datasets` section are in your `1_Data` folder.

2. Open a new R script and save it as a new file called `Prediction_practical.R` in the `2_Code` folder.

3. Using `library()` load the set of packages for this practical listed in the packages section above.

```{r, echo = TRUE, eval = TRUE, message = FALSE}
# Load packages necessary for this script
library(rpart.plot)
library(tidyverse)
library(tidymodels)
tidymodels_prefer() # to resolve common conflicts
```

4. We will again work with the `airbnb` data. Load the dataset using the code below.

```{r, echo = TRUE, eval = FALSE, message = FALSE, warning = FALSE}
# airbnb data
airbnb <- read_csv(file = "1_Data/airbnb.csv")
```


```{r, echo = FALSE, eval = TRUE}
# airbnb data
airbnb <- read_csv(file = "1_Data/airbnb.csv")
```

5. You should already be familiar with the dataset, but you can refresh your memory by checking the variable names with `names()` and the contents using `View()`.

### B - Splitting the data into training and test set

1. In the previous practical, we used the complete `airbnb` dataset to fit the models. To avoid over-fitting, we will now split the data into a training- and a test-set. Use the `initial_split()` function to create a split. Pass it the `airbnb` data as argument and save the output as `airbnb_split`.

```{r, echo = TRUE, eval = FALSE}
# initialize split
XXX <- XXX(XXX)
```

```{r}
airbnb_split <- initial_split(airbnb)
```

2. Create a training-set using the `training()` function. Pass it the `airbnb_split` object as argument and save the output as `airbnb_train`.

```{r, echo = TRUE, eval = FALSE}
# training data
XXX <- XXX(XXX)
```

```{r}
airbnb_train <- training(airbnb_split)
```

3. Create a test-set using the `testing()` function. Pass it the `airbnb_split` object as argument and save the output as `airbnb_test`.

```{r, echo = TRUE, eval = FALSE}
# test data
XXX <- XXX(XXX)
```

```{r}
airbnb_test <- testing(airbnb_split)
```


### B - Fitting

Your goal in this set of tasks is again to fit models predicting `price`, the price of Airbnbs located in Berlin.

#### Regression

1. Define a recipe called `lm_recipe` by calling the `recipe()` function. Use all available predictors by setting the formula to `price ~ .` and use the `airbnb_train` data. Also, add a pipe (`%>%`) and `step_dummy(all_nominal_predictors())` to dummy-code all categorical predictors.


```{r, echo = TRUE, eval = FALSE}
# create recipe
XXX <- 
  XXX(XXX, data = XXX) %>% 
  XXX(XXX())
```

```{r}
# create recipe
lm_recipe <- 
  recipe(price ~ ., data = airbnb) %>% 
  step_dummy(all_nominal_predictors())
```

2. Print the recipe.

```{r}
lm_recipe
```


3. Create a regression model by

- calling the `linear_reg()` function.
- adding a pipe and setting the enginge to `"lm"` using `set_engine()`.
- specifying the problem mode to `"regression"` using `set_mode()`.
- saving the output as `lm_model`.

```{r, echo = TRUE, eval = FALSE}
# set up the regression model
XXX <- 
  XXX() %>% 
  XXX(XXX) %>% 
  XXX(XXX)
```

```{r}
# set up the regression model
lm_model <- 
  linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode("regression")
```

4. Print the model.

```{r}
lm_model
```

5. Create a workflow called `lm_workflow` using `workflow()` and add the `lm_recipe` and `lm_model` objects using `add_recipe()` and `add_model()`.

```{r, echo = TRUE, eval = FALSE}
# lm workflow 
lm_workflow <- 
  XXX() %>% 
  XXX(XXX) %>% 
  XXX(XXX)
```

```{r}
# lm workflow 
lm_workflow <- 
  workflow() %>% 
  add_recipe(lm_recipe) %>% 
  add_model(lm_model)
```

6. Print the workflow.

```{r}
lm_workflow
```

7. Fit the model on the training data by passing the `lm_workflow` and the `aribnb_train` data to the `fit()` function and save the output as `price_lm`.

```{r}
# Fit the regression model
XXX <-
  XXX %>% 
  XXX(XXX)
```

```{r}
# Fit the regression model
price_lm <-
  lm_workflow %>% 
  fit(airbnb_train)
```


8. Using the `tidy()` function on the `price_lm` object, take a look at the parameter estimates.


```{r}
# regression model parameters
tidy(price_lm)
```


9. Using the `predict()` function, to extract the model predictions from `price_lm` and bind them together with the true values from `airbnb_train` using `bind_cols()`.

```{r, echo = TRUE, eval = FALSE}
# get predicted values from training data
lm_pred <-
  XXX %>% 
  XXX(XXX) %>% 
  XXX(airbnb_train %>% select(price))
```

```{r}
# get predicted values from training data
lm_pred <-
  price_lm %>% 
  predict(new_data = airbnb_train) %>% 
  bind_cols(airbnb_train %>% select(price))
```


10. Using the `metrics()` function, evaluate the model performance. Pass it the `price` variable as `truth` and the `.pred` variable as `estimate`.

```{r, echo = TRUE, eval = FALSE}
# evaluate performance
XXX(lm_pred, truth = XXX, estimate = XXX)
```

```{r}
# evaluate performance
metrics(lm_pred, truth = price, estimate = .pred)

```

11. Using the following code, plot the fitted against the true value, to judge how well our model performed.

```{r, echo = TRUE, eval = FALSE}
# use the lm_pred object to generate the plot
ggplot(lm_pred, aes(x = .pred, y = price)) + 
  # Create a diagonal line:
  geom_abline(lty = 2) + 
  # Add data points:
  geom_point(alpha = 0.5) + 
  labs(title = "Regression: All Features",
       subtitle = "Line indicates perfect performance",
       x = "Predicted Airbnb Prices in $",
       y = "True Airbnb Prices in $") +
  # Scale and size the x- and y-axis uniformly:
  coord_obs_pred()
```

#### Decision Trees

12. Decision trees don't need categorical variables to be dummy coded. Create a new recipe called `tree_recipe` that uses all available predictors to predict the `price` of Airbnbs based on the `airbnb_train` data. In addition, use the pre-proccessing step `step_other(all_nominal_predictors(), threshold = 0.005)`. This will lump together all cases of categorical variables that make up less than 0.5% of the cases into an `other` category. This will prevent issues when assessing performance using the test set.

```{r}
tree_recipe <-
  recipe(price ~ ., data = airbnb_train) %>% 
  step_other(all_nominal_predictors(), threshold = 0.005)
```

13. Set up a decision tree model. Use the `decision_tree()` function to specify the model, and set the engine to `rpart`. Set the mode to `"regression"`. Call the output `dt_model`.

```{r, echo = TRUE, eval = FALSE}
# set up the decision tree model
XXX <- 
  XXX() %>% 
  XXX(XXX) %>% 
  XXX(XXX)
```

```{r}
# set up the decision tree model
dt_model <- 
  decision_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("regression")
```

14. Create a new workflow `dt_workflow`, where you add the newly created `tree_recipe` and the `dt_model`.

```{r, echo = TRUE, eval = FALSE}
# decision tree workflow 
dt_workflow <- 
  XXX() %>% 
  XXX(XXX) %>% 
  XXX(XXX)
```

```{r}
# decision tree workflow  
dt_workflow <- 
  workflow() %>% 
  add_recipe(tree_recipe) %>% 
  add_model(dt_model)
```

15. Print the workflow.

```{r}
dt_workflow
```

16. Fit the model on the training data by passing the `dt_workflow` and the `aribnb_train` data to the `fit()` function and save the output as `price_dt`.

```{r}
# Fit the decision tree
XXX <-
  XXX %>% 
  XXX(XXX)
```

```{r}
# Fit the decision tree
price_dt <-
  dt_workflow %>% 
  fit(airbnb_train)
```


17. The `tidy()` function won't work with decision tree fit objects, but we can print the output using the following code:


```{r}
# print the decision tree output
price_dt %>% 
  extract_fit_parsnip() %>% 
  pluck("fit")
```

18. Alternatively, we can pass the object you printed in the previous task in the `rpart.plot` function. This will create a visualization of the decision tree (in this case, the plot does not look very usefull, but depending on the variables used by the model it can be).

```{r}
price_dt %>% 
  extract_fit_parsnip() %>% 
  pluck("fit") %>% 
  rpart.plot()
```


19. Using the `predict()` function, to extract the model predictions from `price_dt` and bind them together with the true values from `airbnb_train` using `bind_cols()`.

```{r, echo = TRUE, eval = FALSE}
# get predicted values from training data
dt_pred <-
  XXX %>% 
  XXX(XXX) %>% 
  XXX(airbnb_train %>% select(price))
```

```{r}
# get predicted values from training data
dt_pred <-
  price_dt %>% 
  predict(new_data = airbnb_train) %>% 
  bind_cols(airbnb_train %>% select(price))
```


20. Using the `metrics()` function, evaluate the model performance. Pass it the `price` variable as `truth` and the `.pred` variable as `estimate`.

```{r, echo = TRUE, eval = FALSE}
# evaluate performance
XXX(dt_pred, truth = XXX, estimate = XXX)
```

```{r}
# evaluate performance
metrics(dt_pred, truth = price, estimate = .pred)

```

21. How does the model performance of the decision tree compare to the one of the regression model, based on the training data?


22. Using the following code, plot the fitted against the true value, to judge how well our model performed.

```{r, echo = TRUE, eval = FALSE}
# use the dt_pred object to generate the plot
ggplot(dt_pred, aes(x = .pred, y = price)) + 
  # Create a diagonal line:
  geom_abline(lty = 2) + 
  # Add data points:
  geom_point(alpha = 0.5) + 
  labs(title = "Decision Tree: All Features",
       subtitle = "Line indicates perfect performance",
       x = "Predicted Airbnb Prices in $",
       y = "True Airbnb Prices in $") +
  # Scale and size the x- and y-axis uniformly:
  coord_obs_pred()
```


#### Random Forests

22. As random forests are made up of many decision trees, we can use the recipe we defined for the decision tree, so we only have to set up a random forest model. Use the `rand_forest()` function to specify the model, and set the engine to `"ranger"`. Set the mode to `"regression"`. Call the output `rf_model`.

```{r, echo = TRUE, eval = FALSE}
# set up the random forest model
XXX <- 
  XXX() %>% 
  XXX(XXX) %>% 
  XXX(XXX)
```

```{r}
# set up the random forest model
rf_model <- 
  rand_forest() %>% 
  set_engine("ranger") %>% 
  set_mode("regression")
```

23. Create a new workflow `rf_workflow`, where you add the `tree_recipe` and the newly created `rf_model`.

```{r, echo = TRUE, eval = FALSE}
# random forest workflow 
rf_workflow <- 
  XXX() %>% 
  XXX(XXX) %>% 
  XXX(XXX)
```

```{r}
# random forest workflow  
rf_workflow <- 
  workflow() %>% 
  add_recipe(tree_recipe) %>% 
  add_model(rf_model)
```

24. Print the workflow.

```{r}
rf_workflow
```

25. Fit the model on the training data by passing the `rf_workflow` and the `aribnb_train` data to the `fit()` function and save the output as `price_rf`.

```{r}
# Fit the random forest
XXX <-
  XXX %>% 
  XXX(XXX)
```

```{r}
# Fit the random forest
price_rf <-
  rf_workflow %>% 
  fit(airbnb_train)
```


26. The `tidy()` function won't work with random forest fit objects, but we can print the output using the following code:


```{r}
# print the random forest output
price_rf %>% 
  extract_fit_parsnip() %>% 
  pluck("fit")
```

27. Using the `predict()` function, to extract the model predictions from `price_rf` and bind them together with the true values from `airbnb_train` using `bind_cols()`.

```{r, echo = TRUE, eval = FALSE}
# get predicted values from training data
rf_pred <-
  XXX %>% 
  XXX(XXX) %>% 
  XXX(airbnb_train %>% select(price))
```

```{r}
# get predicted values from training data
rf_pred <-
  price_rf %>% 
  predict(new_data = airbnb_train) %>% 
  bind_cols(airbnb_train %>% select(price))
```


28. Using the `metrics()` function, evaluate the model performance. Pass it the `price` variable as `truth` and the `.pred` variable as `estimate`.

```{r, echo = TRUE, eval = FALSE}
# evaluate performance
XXX(rf_pred, truth = XXX, estimate = XXX)
```

```{r}
# evaluate performance
metrics(rf_pred, truth = price, estimate = .pred)

```

29. How does the training performance of the random forest compare to the ones of the other two models?


30. Using the following code, plot the fitted against the true value, to judge how well our model performed.

```{r, echo = TRUE, eval = FALSE}
# use the rf_pred object to generate the plot
ggplot(rf_pred, aes(x = .pred, y = price)) + 
  # Create a diagonal line:
  geom_abline(lty = 2) + 
  # Add data points:
  geom_point(alpha = 0.5) + 
  labs(title = "Random Forest: All Features",
       subtitle = "Line indicates perfect performance",
       x = "Predicted Airbnb Prices in $",
       y = "True Airbnb Prices in $") +
  # Scale and size the x- and y-axis uniformly:
  coord_obs_pred()
```

### C - Prediction

1. Before we compared the training performances. Now, let's compare the out-of-sample performances on the test-set. First the linear regression. Using the `predict()` function, to extract the model predictions from `price_lm`, but this time based on `airbnb_test` and bind them together with the true values from `airbnb_test` using `bind_cols()`. Save the output as `lm_pred_test`

```{r, echo = TRUE, eval = FALSE}
# get predicted values from test data
lm_pred_test <-
  XXX %>% 
  XXX(XXX) %>% 
  XXX(airbnb_test %>% select(price))
```

```{r}
# get predicted values from test data
lm_pred_test <-
  price_lm %>% 
  predict(new_data = airbnb_test) %>% 
  bind_cols(airbnb_test %>% select(price))
```

2. Repeat the step above with the decision tree and random forest fits, to create `dt_pred_test` and `rf_pred_test`.

```{r}
# decision tree
dt_pred_test <-
  price_dt %>% 
  predict(new_data = airbnb_test) %>% 
  bind_cols(airbnb_test %>% select(price))

# random forest
rf_pred_test <-
  price_rf %>% 
  predict(new_data = airbnb_test) %>% 
  bind_cols(airbnb_test %>% select(price))
```

3. Using the `metrics()` function, evaluate the models' out-of-sample performances. Pass it the `price` variable as `truth` and the `.pred` variable as `estimate`.

```{r, echo = TRUE, eval = FALSE}
# evaluate performance
XXX(XXX, truth = XXX, estimate = XXX)
XXX(XXX, truth = XXX, estimate = XXX)
XXX(XXX, truth = XXX, estimate = XXX)
```

```{r}
# evaluate performance
metrics(lm_pred_test, truth = price, estimate = .pred)
metrics(dt_pred_test, truth = price, estimate = .pred)
metrics(rf_pred_test, truth = price, estimate = .pred)
```

4. Which model performs the best based on the test data? 

```{r}
# The random forest predictions are still the most accurate.
```

5. Which performance stays the most constant?

```{r}
# The regression model's performance is very similar in the training and 
# test data. The test performance of the decision tree drops somewhat and
# the test performance of the random forest has the most significant drop
# in comparison to it's training performance.
```

5. Which of the three models has the best prediction performance?

```{r}
# The random forest predictions are still the most accurate.
```


### D - Classification

1. Let's again turn to a classification example. We will again focus on the `host_superhost` variable. Like in the previous practical, we first have to change our criterion to be a `factor`. We again explicitly specify `TRUE` as first level.

```{r, echo = TRUE}
# Recode host_superhost to be a factor with TRUE as first level
airbnb <-
  airbnb %>% 
  mutate(host_superhost = factor(host_superhost, levels = c(TRUE, FALSE)))
```

2. Create a split that balances the proportion of the two levels of `host_superhost` and that uses 80% of the data for the training.

```{r, echo = TRUE, eval = FALSE}
airbnb_split <- initial_split(XXX, prop = XXX, strata = XXX)
```

```{r}
airbnb_split <- initial_split(airbnb, prop = .8, strata = host_superhost)
```

3. From the initial split object, creat a training and a test set, and save them as `airbnb_train` and `airbnb_test`.

```{r, echo = TRUE, eval = FALSE}
XXX <- XXX(XXX)
XXX <- XXX(XXX)
```

```{r}
airbnb_train <- training(airbnb_split)
airbnb_test <- testing(airbnb_split)
```


### F - Fitting

#### Regression

1. Specify the recipe for a logistic regression. Specifically...

- set the formula to `host_superhost ~ .`, to use all possible features
- use the `airbnb_train` data
- add `step_dummy(all_nominal_predictors())` to pre-process nominal features
- call the new object `logistic_recipe`


```{r, echo = TRUE, eval = FALSE}
# create new recipe
XXX <- 
  XXX(XXX, data = XXX) %>% 
  XXX(XXX())
```

```{r}
# create new recipe
logistic_recipe <- 
  recipe(host_superhost ~ ., data = airbnb_train) %>% 
  step_dummy(all_nominal_predictors())
```

2. Print the new recipe.

```{r}
logistic_recipe
```


3. Create a new model called `logistic_model`, with the model type `logistic_reg`, the engine `"glm"`, and mode `"classification"`.

```{r, echo = TRUE, eval = FALSE}
# create a logistic regression model 
XXX_model <-
  XXX() %>% 
  set_XXX(XXX) %>% 
  set_XXX(XXX)
```


```{r}
# create a logistic regression model 
logistic_model <-
  logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")
```

4. Create a new workflow called `logistic_workflow`, where you add the `logistic_model` and the `logistic_recipe` together.

```{r}
# create logistic_workflow 
logistic_workflow <- 
  workflow() %>% 
  add_recipe(logistic_recipe) %>% 
  add_model(logistic_model)
```

6. Fit the model on the training data (`airbnb_train`) using `fit()`. Save the result as `superhost_glm`.

```{r}
# Fit the logistic regression model
superhost_glm <-
  logistic_workflow %>% 
  fit(airbnb_train)
```

7. Evaluate the training performance with the `metrics()` function to do so. First, we again create a dataset containing the predicted and true values. This time, we call the `predict()` function twice: once to obtain the predicted classes, and once to obtain the probabilities, with which the classes are predicted.

```{r, echo = TRUE, eval = FALSE}
# Get fitted values from the Private_glm object
logistic_pred <- 
  predict(superhost_glm, airbnb_train, type = "prob") %>% 
  bind_cols(predict(superhost_glm, airbnb_train)) %>% 
  bind_cols(airbnb_train %>% select(host_superhost))
```

```{r}
# Get fitted values from the Private_glm object
logistic_pred <- 
  predict(superhost_glm, airbnb_train, type = "prob") %>% 
  bind_cols(predict(superhost_glm, airbnb_train)) %>% 
  bind_cols(airbnb_train %>% select(host_superhost))
```


8. Let's look at different performance metrics. Use the `metrics()` function and pass it the `host_superhost` variable as `truth`, the `.pred_class` variable as `estimate`, and `.pred_TRUE` as last argument.

```{r, echo = TRUE, eval = FALSE}
XXX(logistic_pred, truth = XXX, estimate = XXX, XXX)
```

```{r}
metrics(logistic_pred, truth = host_superhost, estimate = .pred_class, .pred_TRUE)
```


9. Plot the ROC-curve using the `roc_curve()` function, to create sensitivity and specificity values of different cut-offs, and pass this into the `autoplot()` function, to plot the curve. Add the `host_superhost` column as `truth`, and the `.pred_TRUE` column as third, unnamed argument, to the `roc_curve()` function and plot the curve.

```{r, echo = TRUE, eval = FALSE}
XXX(logistic_pred, truth = XXX, XXX) %>% 
  autoplot()
```

```{r}
roc_curve(logistic_pred, truth = host_superhost, .pred_TRUE) %>% 
  autoplot()
```

#### Decision Tree

10. Create a new recipe called `tree_recipe` that uses all available predictors to predict `host_superhost`. In addition, again use the pre-processing step `step_other(all_nominal_predictors(), threshold = 0.005)`.

```{r}
tree_recipe <-
  recipe(host_superhost ~ ., data = airbnb_train) %>% 
  step_other(all_nominal_predictors(), threshold = 0.005)
```

11. Set up a decision tree model. Use the `decision_tree()` function to specify the model, and set the engine to `rpart`. Set the mode to `"classification"`. Call the output `dt_model`.


```{r}
# set up the decision tree model
dt_model <- 
  decision_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("classification")
```

12. Create a new workflow `dt_workflow`, where you add the newly created `tree_recipe` and the `dt_model`.


```{r}
# decision tree workflow  
dt_workflow <- 
  workflow() %>% 
  add_recipe(tree_recipe) %>% 
  add_model(dt_model)
```

13. Print the workflow.

```{r}
dt_workflow
```

14. Fit the model on the training data by passing the `dt_workflow` and the `aribnb_train` data to the `fit()` function and save the output as `superhost_dt`.

```{r}
# Fit the decision tree
superhost_dt <-
  dt_workflow %>% 
  fit(airbnb_train)
```

15. Evaluate the training performance with the `metrics()` function to do so. Use the code from the logistic regression above as template. Save the output as `dt_pred`.


```{r}
dt_pred <- 
  predict(superhost_dt, airbnb_train, type = "prob") %>% 
  bind_cols(predict(superhost_dt, airbnb_train)) %>% 
  bind_cols(airbnb_train %>% select(host_superhost))
```


16. Let's look at different performance metrics. Use the `metrics()` function and pass it the `host_superhost` variable as `truth`, the `.pred_class` variable as `estimate`, and `.pred_TRUE` as last argument.


```{r}
metrics(dt_pred, truth = host_superhost, estimate = .pred_class, .pred_TRUE)
```


17. Plot the ROC-curve using the `roc_curve()` function, to create sensitivity and specificity values of different cut-offs, and pass this into the `autoplot()` function, to plot the curve. Add the `host_superhost` column as `truth`, and the `.pred_TRUE` column as third, unnamed argument, to the `roc_curve()` function and plot the curve.

```{r}
roc_curve(dt_pred, truth = host_superhost, .pred_TRUE) %>% 
  autoplot()
```


#### Random Forest

18. Set up a random forest classification model. Use the `rand_forest()` function to specify the model, and set the engine to `ranger`. Set the mode to `"classification"`. Call the output `rf_model`.


```{r}
# set up the random forest model
rf_model <- 
  rand_forest() %>% 
  set_engine("ranger") %>% 
  set_mode("classification")
```

19. Create a new workflow `rf_workflow`, where you add the previously created `tree_recipe` and the new `rf_model`.


```{r}
# random forest workflow  
rf_workflow <- 
  workflow() %>% 
  add_recipe(tree_recipe) %>% 
  add_model(rf_model)
```

20. Print the workflow.

```{r}
rf_workflow
```

21. Fit the model on the training data by passing the `rf_workflow` and the `aribnb_train` data to the `fit()` function and save the output as `superhost_rf`.

```{r}
# Fit the random forest
superhost_rf <-
  rf_workflow %>% 
  fit(airbnb_train)
```

22. Evaluate the training performance with the `metrics()` function to do so and save the output as `rf_pred`.


```{r}
rf_pred <- 
  predict(superhost_rf, airbnb_train, type = "prob") %>% 
  bind_cols(predict(superhost_rf, airbnb_train)) %>% 
  bind_cols(airbnb_train %>% select(host_superhost))
```


23. Let's look at different performance metrics. Use the `metrics()` function and pass it the `host_superhost` variable as `truth`, the `.pred_class` variable as `estimate`, and `.pred_TRUE` as last argument.


```{r}
metrics(rf_pred, truth = host_superhost, estimate = .pred_class, .pred_TRUE)
```

24. Plot the ROC-curve using the `roc_curve()` function, to create sensitivity and specificity values of different cut-offs, and pass this into the `autoplot()` function, to plot the curve.

```{r}
roc_curve(rf_pred, truth = host_superhost, .pred_TRUE) %>% 
  autoplot()
```

### G - Prediction

1. Before we compared the training performances. Now, let's compare the out-of-sample performances on the test-set. First the logistic regression. Using the `predict()` function twice to extract the model predictions from `superhost_glm` (as done with the training data), but this time based on `airbnb_test` and bind them together with the true values from `airbnb_test` using `bind_cols()`. Save the output as `glm_pred_test`


```{r}
# get predicted values from test data
glm_pred_test <-
  superhost_glm %>% 
  predict(airbnb_test, type = "prob") %>% 
  bind_cols(predict(superhost_glm, airbnb_test)) %>% 
  bind_cols(airbnb_test %>% select(host_superhost))
```

2. Repeat the step above with the decision tree and random forest fits, to create `dt_pred_test` and `rf_pred_test`.

```{r}
# decision tree
dt_pred_test <-
  superhost_dt %>% 
  predict(airbnb_test, type = "prob") %>% 
  bind_cols(predict(superhost_dt, airbnb_test)) %>% 
  bind_cols(airbnb_test %>% select(host_superhost))

# random forest
rf_pred_test <-
  superhost_rf %>% 
  predict(airbnb_test, type = "prob") %>% 
  bind_cols(predict(superhost_rf, airbnb_test)) %>% 
  bind_cols(airbnb_test %>% select(host_superhost))
```

3. Using the `metrics()` function, evaluate the models' out-of-sample performances. Pass it the `price` variable as `truth` and the `.pred` variable as `estimate`.


```{r}
# evaluate performance
metrics(glm_pred_test, truth = host_superhost, estimate = .pred_class, .pred_TRUE)
metrics(dt_pred_test, truth = host_superhost, estimate = .pred_class, .pred_TRUE)
metrics(rf_pred_test, truth = host_superhost, estimate = .pred_class, .pred_TRUE)
```

4. Which model performs the best based on the test data? 

```{r}
# The random forest predictions are still the most accurate.
```

5. Plot the ROC-curves of the test performances.
```{r}
roc_curve(glm_pred_test, truth = host_superhost, .pred_TRUE) %>% 
  autoplot()
roc_curve(dt_pred_test, truth = host_superhost, .pred_TRUE) %>% 
  autoplot()
roc_curve(rf_pred_test, truth = host_superhost, .pred_TRUE) %>% 
  autoplot()
```


## Examples

```{r, eval = FALSE, echo = TRUE}
# Fitting and evaluating a regression model ------------------------------------

# Step 0: Load packages---------------------------------------------------------
library(tidyverse)    # Load tidyverse for dplyr and tidyr
library(tidymodels)   # For ML mastery 
tidymodels_prefer()   # To resolve common conflicts

# Step 1: Load and Clean, and Explore Training data ----------------------------

# I'll use the mpg dataset from the dplyr package 
# Explore training data
mpg        # Print the dataset
View(mpg)  # Open in a new spreadsheet-like window 
dim(mpg)   # Print dimensions
names(mpg) # Print the names

# Step 2: Split the data--------------------------------------------------------

mpg_split <- initial_split(mpg)
data_train <- training(mpg_split)
data_test <- testing(mpg_split)

# Step 3: Define recipe --------------------------------------------------------

# The recipe defines what to predict with what, and how to pre-process the data
lm_recipe <- 
  recipe(hwy ~ year + cyl + displ + trans,  # Specify formula
         data = data_train) %>%             # Specify the data
  step_dummy(all_nominal_predictors())      # Dummy code all categorical predictors


# Step 4: Define model ---------------------------------------------------------

# The model definition defines what kind of model we want to use and how to
# fit it
lm_model <- 
  linear_reg() %>%        # Specify model type
  set_engine("lm") %>%    # Specify engine (often package name) to use
  set_mode("regression")  # Specify whether it's a regressio or classification
                          #  problem.

# Step 5: Define workflow ------------------------------------------------------

# The workflow combines model and recipe, so that we can fit the model
lm_workflow <- 
  workflow() %>%             # Initialize workflow
  add_model(lm_model) %>%    # Add the model to the workflow
  add_recipe(lm_recipe)      # Add the recipe to the workflow

# Step 6: Fit the model --------------------------------------------------------

hwy_lm <- 
  lm_workflow %>%   # Use the specified workflow
  fit(data_train)   # Fit the model on the specified data

tidy(hwy_lm)        # Look at summary information

# Step 7: Assess fit -----------------------------------------------------------

# Save model predictions and observed values
lm_fitted <- 
  hwy_lm %>%               # Model from which to extract predictions
  predict(data_train) %>%  # Obtain predictions, based on entered data (in this
                           #  case, these predictions are not out-of-sample)
  bind_cols(data_train %>% select(hwy))  # Extract observed/true values

# Obtain performance metrics
metrics(lm_fitted, truth = hwy, estimate = .pred)

# Step 8: Assess prediction performance ----------------------------------------
# Save model predictions and observed values
lm_pred <- 
  hwy_lm %>%               # Model from which to extract predictions
  predict(data_test) %>%   # Obtain predictions, based on entered data (in this
                           #  case, these predictions ARE out-of-sample)
  bind_cols(data_test %>% select(hwy))  # Extract observed/true values

# Obtain performance metrics
metrics(lm_pred, truth = hwy, estimate = .pred)
```



## Datasets

```{r, eval = TRUE, message = FALSE, echo = FALSE}
library(tidyverse)
library(tidymodels)
```

|File  |Rows | Columns |
|:----|:-----|:------|
|[airbnb.csv](https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/college_train.csv?token=AGKBX5SLEV3PLWUVQ4NCUB2427V36)| 7609 | 30|


#### Variable description of `airbnb`

| Name | Description |
|:-------------|:-------------------------------------|
|price| Price per night (in \$s)|
|date| When apartment was added to Airbnb |
|room_type| Apartment, Loft, House, etc.|
|accommodates| Number of people the airbnb accommodates |
|bedrooms| Number of bedrooms |
|bathrooms| Number of bathrooms |
|cleaning_fee| Amount of cleaning fee (in \$s) |
|availability_90_days| How many of the following 90 days the airbnb is available |
|neighbourhood| The neighbourhood the Airbnb is located in |
|district| The district the Airbnb is located in |
|host_since| Experience of the hosts |
|host_respons_time| Host average response time|
|host_response_rate| Host response rate |
|host_superhost| Whether host is a superhost TRUE/FALSE |
|host_listings_count| Number of listings the host has |
|review_scores_rating| Overall rating [0, 100]|
|review_scores_accuracy| Accuracy of information rating [0, 10] |
|review_scores_cleanliness| Cleanliness rating  [0, 10]|
|review_scores_checkin| Check in rating [0, 10] |
|review_scores_communication| Communication rating [0, 10] |
|review_scores_location| Location rating [0, 10] |
|review_scores_value| Value rating [0, 10] |
|kitchen| Kitchen available TRUE/FALSE |
|wifi| Wifi available TRUE/FALSE |
|tv| TV available TRUE/FALSE |
|coffe_machine| Coffee machine available TRUE/FALSE|
|dishwasher| Dishwasher available TRUE/FALSE|
|terrace| Terrace/balcony available TRUE/FALSE|
|bathtub| Bathtub available TRUE/FALSE|
|check_in_24h| 24h Check-In available TRUE/FALSE|


## Functions

### Packages

|Package| Installation|
|:------|:------|
|`tidyverse`|`install.packages("tidyverse")`|
|`tidymodels`|`install.packages("tidymodels")`|
|`rpart.plot`|`install.packages("rpart.plot")`|

### Functions

| Function| Package | Description |
|:---|:------|:---------------------------------------------|
| `read_csv()`|`tidyverse`|    Read in data| 
| `mutate()`|`tidyverse`|    Manipulate or create columns| 
| `bind_cols()`|`tidyverse`|    Bind columns together and return a tibble| 
| `pluck()` | `tidyverse` | Extract element from list|
| `initial_split()` | `tidymodels`|    Initialize splitting dataset into training and test data|
| `training()` | `tidymodels`|    Create training data from `initial_split` output|
| `testing()` | `tidymodels`|    Create training data from `initial_split` output|
| `linear_reg()`/`logistic_reg()`|`tidymodels`|    Initialize linear/logistic regression model| 
| `set_engine()`|`tidymodels`|    Specify which engine to use for the modeling (e.g., "lm" to use `stats::lm()`, or "stan" to use `rstanarm::stan_lm()`)| 
| `set_mode()`|`tidymodels`|    Specify whether it's a regression or classification problem| 
| `recipe()`|`tidymodels`|    Initialize recipe| 
| `step_dummy()`|`tidymodels`|    pre-process data into dummy variables| 
| `workflow()`|`tidymodels`|   Initialize workflow| 
| `add_recipe()`|`tidymodels`|   Add recipe to workflow|
| `update_recipe()`|`tidymodels`|   Update workflow with a new recipe|
| `add_model()`|`tidymodels`|   Add model to workflow| 
| `fit()`|`tidymodels`|   Fit model| 
| `tidy()`|`tidymodels`|   Show model parameters| 
| `predict()`|`tidymodels`|   Create model predictions based on specified data| 
| `metrics()`|`tidymodels`|   Evaluate model performance| 
| `conf_mat()`|`tidymodels`|   Create confusion matrix| 
| `roc_curve()`|`tidymodels`|   Calculate sensitivity and specificity with different thresholds for ROC-curve| 
| `autoplot()`|`tidymodels`|   Plot methods for different objects such as those created from `roc_curve()` to plot the ROC-curve| 
| `rpart.plot()`| `rpart.plot` | Plot a decision tree from an `rpart` fit object|



## Resources

- [**tidymodels webpage**](https://www.tidymodels.org/): Can be used as cheat sheet. Also has some tutorials.
- The, not yet completed, book [**Tidymodeling with R**](https://www.tmwr.org): More detailed introduction into the `tidymodels` framework.
